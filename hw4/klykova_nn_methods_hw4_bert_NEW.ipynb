{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaklykova/neuromethods/blob/main/hw4/klykova_nn_methods_hw4_bert_NEW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20101271",
      "metadata": {
        "id": "20101271"
      },
      "source": [
        "# Д/З 4: использование BERT для классификации последовательности\n",
        "### Выполнила Елизавета Клыкова, БКЛ181"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "kPLAbc-xdb4Z"
      },
      "id": "kPLAbc-xdb4Z"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "90d34261",
      "metadata": {
        "id": "90d34261"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0caa1c8a",
      "metadata": {
        "id": "0caa1c8a"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, Trainer, TrainingArguments, \\\n",
        "    BertForSequenceClassification\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pylab import rcParams\n",
        "from textwrap import wrap\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
        "    precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9056999d",
      "metadata": {
        "id": "9056999d"
      },
      "outputs": [],
      "source": [
        "seed = 117\n",
        "# random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda') if torch.cuda.is_available()\\\n",
        "                              else torch.device('cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ohlV3fn5Qz",
        "outputId": "fd8cbafc-f983-4b9b-eef9-a4a4880bb995"
      },
      "id": "J8ohlV3fn5Qz",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка датасета"
      ],
      "metadata": {
        "id": "VbTnVj2rn9kx"
      },
      "id": "VbTnVj2rn9kx"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73d9c2f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73d9c2f4",
        "outputId": "795c868b-e02b-4391-b9e5-de78a78d718a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 74.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "100% 7.17M/7.17M [00:00<00:00, 167MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef6bc8f1",
      "metadata": {
        "id": "ef6bc8f1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотрим на распределение классов, балансируем датасет:"
      ],
      "metadata": {
        "id": "MqQDfLo1c8oy"
      },
      "id": "MqQDfLo1c8oy"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9fcda166",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "9fcda166",
        "outputId": "5f958547-c164-4d47-bdae-bd966a3656a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'review score')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0a9f4c8f",
      "metadata": {
        "id": "0a9f4c8f"
      },
      "outputs": [],
      "source": [
        "def to_sentiment(rating):\n",
        "    rating = int(rating)\n",
        "    if rating <= 2:\n",
        "        return 0\n",
        "    elif rating == 3:\n",
        "        return 1\n",
        "    else: \n",
        "        return 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "metadata": {
        "id": "Cc6HjIkjc64A"
      },
      "id": "Cc6HjIkjc64A",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d1f2a648",
      "metadata": {
        "id": "d1f2a648"
      },
      "outputs": [],
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "82d51efc",
      "metadata": {
        "id": "82d51efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "5acb770c-3c3d-4861-9e3f-67c7b701552c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'negative'), Text(0, 0, 'neutral'), Text(0, 0, 'positive')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Требования\n",
        "Решите задачу классификации по тональности на подготовленном в тетрадке корпусе, используя пайплайн с Trainer от HuggingFace.\n",
        "\n",
        "1. DONE обучите ту модель, которую мы разбирали на занятии (класс SentimentClassifier из тетрадки) -- 2 балла\n",
        "\n",
        "2. DONE измените модель, чтобы помимо выхода с пуллер-слоя использовался эмбеддинг cls-токена с последнего слоя. -- 3 балла\n",
        "\n",
        "3. DONE примените к данным готовую модель для классификации последовательности (типа BertForSequenceClassification) -- 2 балла\n",
        "\n",
        "4. DONE агрегируйте cls-токены для нескольких слоев, чтобы сделать предсказание класса -- 2 дополнительных балла\n",
        "\n",
        "5. DONE выберите на сайте google play три понравившихся вам отзыва, относящиеся к разным классам. Покажите, как на них работает любая из обученных моделей -- 2 балла\n",
        "\n",
        "DONE Общие требования: (1 балл) Для всех моделей используйте одинаковые гиперпараметры, чтобы их результаты можно было сравнить между собой.\n",
        "\n",
        "DONE Комментируйте ваши решения в коде.\n",
        "\n",
        "DONE Для каждой из моделей нужно привести результаты на тестовой выборке.\n",
        "\n",
        "DONE Вы можете использовать любую предобученную модель, которая подходит для работы с английским, кроме bert-base-cased."
      ],
      "metadata": {
        "id": "6jGXSgTfkqT_"
      },
      "id": "6jGXSgTfkqT_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1: Обучить модель с SentimentClassifier (2 балла)"
      ],
      "metadata": {
        "id": "PMff0u3beAJC"
      },
      "id": "PMff0u3beAJC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка данных\n",
        "Делим на тест и трейн:"
      ],
      "metadata": {
        "id": "wDt0IZQJhqhk"
      },
      "id": "wDt0IZQJhqhk"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=seed)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=seed)"
      ],
      "metadata": {
        "id": "TlYtbPKkf7o0"
      },
      "id": "TlYtbPKkf7o0",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я буду использовать модель [prajjwal1/bert-mini](https://huggingface.co/prajjwal1/bert-mini), поскольку она мало весит, а также быстро обучается и работает."
      ],
      "metadata": {
        "id": "ClN1EwTUgIHp"
      },
      "id": "ClN1EwTUgIHp"
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'prajjwal1/bert-mini'"
      ],
      "metadata": {
        "id": "1eoc94I1egTo"
      },
      "id": "1eoc94I1egTo",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "Oux4gJhgeUnL"
      },
      "id": "Oux4gJhgeUnL",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "yk_zE69Ge3W4"
      },
      "id": "yk_zE69Ge3W4",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(df_train['content'].to_list(), truncation=True, \n",
        "                            padding=True, return_token_type_ids=False, \n",
        "                            return_attention_mask=True, max_length=160)\n",
        "val_encodings = tokenizer(df_val['content'].to_list(), truncation=True, \n",
        "                          padding=True, return_token_type_ids=False,\n",
        "                          return_attention_mask=True, max_length=160)\n",
        "test_encodings = tokenizer(df_test['content'].to_list(), truncation=True, \n",
        "                           padding=True, return_token_type_ids=False,\n",
        "                           return_attention_mask=True, max_length=160)"
      ],
      "metadata": {
        "id": "gYjlFAIKghcn"
      },
      "id": "gYjlFAIKghcn",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = GPReviewDataset(train_encodings, df_train['sentiment'].to_list())\n",
        "val_dataset = GPReviewDataset(val_encodings, df_val['sentiment'].to_list())\n",
        "test_dataset = GPReviewDataset(test_encodings, df_test['sentiment'].to_list())"
      ],
      "metadata": {
        "id": "gm0ioS0XfoMz"
      },
      "id": "gm0ioS0XfoMz",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрики и параметры трейнера"
      ],
      "metadata": {
        "id": "199opnMUjB5f"
      },
      "id": "199opnMUjB5f"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds,\n",
        "                                                               average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "p1JV4cbVjF_3"
      },
      "id": "p1JV4cbVjF_3",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры одинаковые для всех моделей, чтобы можно было сравнить результаты:"
      ],
      "metadata": {
        "id": "fg8Mf186BmTU"
      },
      "id": "fg8Mf186BmTU"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=100,\n",
        ")"
      ],
      "metadata": {
        "id": "UTcDnofZj99Q"
      },
      "id": "UTcDnofZj99Q",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель\n",
        "Добавляем в модель подсчет лосса (кросс-энтропию):"
      ],
      "metadata": {
        "id": "J7hNMuinh9dh"
      },
      "id": "J7hNMuinh9dh"
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False)\n",
        "        output = self.drop(pooled_output)\n",
        "        output = self.out(output)\n",
        "        if labels is not None:\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(output, labels)\n",
        "            return loss, output\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "DJ1jqCq0k51q"
      },
      "id": "DJ1jqCq0k51q",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = SentimentClassifier(n_classes=3)\n",
        "model1 = model1.to(DEVICE)"
      ],
      "metadata": {
        "id": "DYk7sd5znS5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa98b94-b160-435c-a624-2d1ecdece79e"
      },
      "id": "DYk7sd5znS5Y",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4a7ea2bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4a7ea2bf",
        "outputId": "022d6fa2-000a-420f-c232-ba52e555c9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.996700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.931800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.968600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.883900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.829400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.825600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.849600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.826700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.782200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.792600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.797600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.769500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.788100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.755000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.702300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.722700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.661000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.629300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.651100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.754000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.662200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.648200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.620300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.616700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.668500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.623000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.598800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.599200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.575200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.536900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.567800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.661800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.526400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.616100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.548800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.585700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.552600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.554500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.573300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.560300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.7124012172266987, metrics={'train_runtime': 263.8687, 'train_samples_per_second': 161.114, 'train_steps_per_second': 20.146, 'total_flos': 0.0, 'train_loss': 0.7124012172266987, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "trainer1 = Trainer(\n",
        "    model=model1,                        # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer1.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оценка"
      ],
      "metadata": {
        "id": "HApSFe_lhvGP"
      },
      "id": "HApSFe_lhvGP"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "1GiIe2nICFwW",
        "outputId": "c449c7c5-fbd7-4406-e4f7-4416ea9ddc37"
      },
      "id": "1GiIe2nICFwW",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7458703939008895,\n",
              " 'eval_f1': 0.7449001912160426,\n",
              " 'eval_loss': 0.6661240458488464,\n",
              " 'eval_precision': 0.7444538860445467,\n",
              " 'eval_recall': 0.7458703939008895,\n",
              " 'eval_runtime': 1.1396,\n",
              " 'eval_samples_per_second': 690.617,\n",
              " 'eval_steps_per_second': 43.877}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_metrics = trainer1.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task1_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "PGihkIHPhiGr",
        "outputId": "382094c5-db15-4c14-c9a6-183161832e7a"
      },
      "id": "PGihkIHPhiGr",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7195431472081218,\n",
              " 'test_f1': 0.7175250820150627,\n",
              " 'test_loss': 0.700705885887146,\n",
              " 'test_precision': 0.7165735299433978,\n",
              " 'test_recall': 0.7195431472081218,\n",
              " 'test_runtime': 1.2779,\n",
              " 'test_samples_per_second': 616.649,\n",
              " 'test_steps_per_second': 39.127}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7195431472081218\n",
        "\n",
        "'test_f1': 0.7175250820150627\n",
        "\n",
        "'test_loss': 0.700705885887146\n",
        "\n",
        "'test_precision': 0.7165735299433978\n",
        "\n",
        "'test_recall': 0.7195431472081218"
      ],
      "metadata": {
        "id": "4m9HZ51juyDL"
      },
      "id": "4m9HZ51juyDL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: Использовать CLS-токен (3 балла)\n",
        "Измените модель, чтобы помимо выхода с пуллер-слоя использовался эмбеддинг cls-токена с последнего слоя."
      ],
      "metadata": {
        "id": "vN7FXr0Ye55d"
      },
      "id": "vN7FXr0Ye55d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "jm_mmdyVhyo2"
      },
      "id": "jm_mmdyVhyo2"
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifierWithCLS(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        # в два раза больше параметров: с пуллер-слоя и CLS\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size * 2, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        last_hidden_state, pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False)\n",
        "        # добавляем выходы с CLS\n",
        "        cls_hidden = last_hidden_state[:, 0, :]\n",
        "        stacked_layers = torch.hstack([cls_hidden, pooled_output])\n",
        "        # дальше все то же самое\n",
        "        output = self.drop(stacked_layers)\n",
        "        output = self.out(output)\n",
        "        if labels is not None:\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(output, labels)\n",
        "            return loss, output\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "PA0YrTzNf696"
      },
      "id": "PA0YrTzNf696",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SentimentClassifierWithCLS(n_classes=3)\n",
        "model2 = model2.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdM1PRluhONp",
        "outputId": "174f2668-52d4-403f-d605-595b52db65f5"
      },
      "id": "fdM1PRluhONp",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-mini.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = Trainer(\n",
        "    model=model2,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer2.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sKYUY_bVhUbN",
        "outputId": "6a6fa63f-5dc8-49db-cf63-35e070ee1e09"
      },
      "id": "sKYUY_bVhUbN",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.142300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.092300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.941400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.910300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.969300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.861200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.834600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.789100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.788600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.778600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.803000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.741300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.716800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.671400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.735600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.688400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.721300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.737400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.645900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.639900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.622800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.724500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.636900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.673400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.644900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.626000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.578900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.558500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.546700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.530200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.564800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.630500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.520700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.609300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.570300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.550800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.537000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.557200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.546700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.7063673872800588, metrics={'train_runtime': 267.5421, 'train_samples_per_second': 158.902, 'train_steps_per_second': 19.87, 'total_flos': 0.0, 'train_loss': 0.7063673872800588, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оценка"
      ],
      "metadata": {
        "id": "MQU4-j_uh1b9"
      },
      "id": "MQU4-j_uh1b9"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ip8K1b5TCJCd",
        "outputId": "1248854a-bf83-4152-8e2e-4d2b3bf74239"
      },
      "id": "ip8K1b5TCJCd",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7534942820838628,\n",
              " 'eval_f1': 0.7510092553606023,\n",
              " 'eval_loss': 0.6870903372764587,\n",
              " 'eval_precision': 0.7505587063502279,\n",
              " 'eval_recall': 0.7534942820838628,\n",
              " 'eval_runtime': 1.14,\n",
              " 'eval_samples_per_second': 690.337,\n",
              " 'eval_steps_per_second': 43.859}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task2_metrics = trainer2.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task2_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "7m4imZCvhZx3",
        "outputId": "11cb9742-bdc9-4cd9-fb9d-3eac85657245"
      },
      "id": "7m4imZCvhZx3",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7271573604060914,\n",
              " 'test_f1': 0.7249801696477138,\n",
              " 'test_loss': 0.7265090346336365,\n",
              " 'test_precision': 0.7244949466213112,\n",
              " 'test_recall': 0.7271573604060914,\n",
              " 'test_runtime': 1.269,\n",
              " 'test_samples_per_second': 620.961,\n",
              " 'test_steps_per_second': 39.401}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7271573604060914\n",
        "\n",
        "'test_f1': 0.7249801696477138\n",
        "\n",
        "'test_loss': 0.7265090346336365\n",
        "\n",
        "'test_precision': 0.7244949466213112\n",
        "\n",
        "'test_recall': 0.7271573604060914"
      ],
      "metadata": {
        "id": "51DhG3BziM9d"
      },
      "id": "51DhG3BziM9d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Применить готовую модель BertForSequenceClassification (2 балла)"
      ],
      "metadata": {
        "id": "IFd2hX7_h_Ak"
      },
      "id": "IFd2hX7_h_Ak"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель\n"
      ],
      "metadata": {
        "id": "M_ySLOPWiIRE"
      },
      "id": "M_ySLOPWiIRE"
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME,\n",
        "                                                       num_labels=3)\n",
        "model3 = model3.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0r-cBl4helm",
        "outputId": "b0b8db73-e296-4efd-9414-b647971e2514"
      },
      "id": "j0r-cBl4helm",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3 = Trainer(\n",
        "    model=model3,                        # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer3.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bC9tM5Ucijy_",
        "outputId": "7baae2c2-f3f2-4682-f999-dc6cc0380767"
      },
      "id": "bC9tM5Ucijy_",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.044900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.946800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.906400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.917000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.845100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.792400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.793800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.815900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.800900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.779000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.785000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.762700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.775500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.737900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.697700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.669600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.714600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.670900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.660900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.666800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.696400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.631500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.656300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.721600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.659000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.627800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.606400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.624000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.674500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.622500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.573000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.568700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.559200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.529800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.604400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.579500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.643000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.611200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.564700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.581500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.544500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.543100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.558600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.531200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.546800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.6979088459452621, metrics={'train_runtime': 270.9737, 'train_samples_per_second': 156.89, 'train_steps_per_second': 19.618, 'total_flos': 131665753915200.0, 'train_loss': 0.6979088459452621, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оценка"
      ],
      "metadata": {
        "id": "mkdykPBNivQA"
      },
      "id": "mkdykPBNivQA"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "sO9uxpfUCMtk",
        "outputId": "656499b9-f7c9-4712-a302-b2b4a801521c"
      },
      "id": "sO9uxpfUCMtk",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7433290978398983,\n",
              " 'eval_f1': 0.7413411404516946,\n",
              " 'eval_loss': 0.6564545631408691,\n",
              " 'eval_precision': 0.740587164439763,\n",
              " 'eval_recall': 0.7433290978398983,\n",
              " 'eval_runtime': 1.1366,\n",
              " 'eval_samples_per_second': 692.418,\n",
              " 'eval_steps_per_second': 43.991}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task3_metrics = trainer3.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task3_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ULb5nVj8im6u",
        "outputId": "19794353-90fa-4f11-e1c0-a3cae779d820"
      },
      "id": "ULb5nVj8im6u",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7182741116751269,\n",
              " 'test_f1': 0.7174620470984623,\n",
              " 'test_loss': 0.6998140811920166,\n",
              " 'test_precision': 0.7169186564878467,\n",
              " 'test_recall': 0.7182741116751269,\n",
              " 'test_runtime': 1.2721,\n",
              " 'test_samples_per_second': 619.469,\n",
              " 'test_steps_per_second': 39.306}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7182741116751269\n",
        "\n",
        "'test_f1': 0.7174620470984623\n",
        "\n",
        "'test_loss': 0.6998140811920166\n",
        "\n",
        "'test_precision': 0.7169186564878467\n",
        "\n",
        "'test_recall': 0.7182741116751269"
      ],
      "metadata": {
        "id": "jZOxM8Y1i-we"
      },
      "id": "jZOxM8Y1i-we"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Агрегировать CLS-токены нескольких слоев (2 бонуса)"
      ],
      "metadata": {
        "id": "tviJ_-eakU3h"
      },
      "id": "tviJ_-eakU3h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "MLWH2A37n3YO"
      },
      "id": "MLWH2A37n3YO"
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifierAllCLS(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # здесь добавились все скрытые слои\n",
        "        last_hidden_state, pooled_output, hidden_states = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False,\n",
        "            output_hidden_states=True)\n",
        "        # добавляем CLS всех скрытых слоев\n",
        "        all_cls_hidden = [layer[:, 0, :] for layer in hidden_states]\n",
        "        # получаем среднее\n",
        "        mean_cls = torch.mean(torch.stack(all_cls_hidden, dim=0), dim=0)\n",
        "        # дальше все стандартно\n",
        "        output = self.drop(mean_cls)\n",
        "        output = self.out(output)\n",
        "        if labels is not None:\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(output, labels)\n",
        "            return loss, output\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "8cAJ6X8jlUNR"
      },
      "id": "8cAJ6X8jlUNR",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = SentimentClassifierAllCLS(n_classes=3)\n",
        "model4 = model4.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6IXtUXpnzTl",
        "outputId": "b73c5f0f-dc99-4071-c311-b82279db605f"
      },
      "id": "O6IXtUXpnzTl",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-mini.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer4 = Trainer(\n",
        "    model=model4,                        # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer4.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WpDBEVtOn7nA",
        "outputId": "efe25207-5d08-43e9-9106-6aad788e7432"
      },
      "id": "WpDBEVtOn7nA",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:22, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.878300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.843500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.841600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.821200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.790500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.788800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.824100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.797200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.770600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.785700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.755200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.729800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.688200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.754700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.683600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.681400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.708400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.654700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.729100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.656500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.650700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.723600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.641400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.670700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.671300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.628400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.593400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.589800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.572900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.628100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.598700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.655500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.554400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.636700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.562100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.592600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.576600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.588500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.582700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.572500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.557100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.574000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.7222974192746336, metrics={'train_runtime': 262.7125, 'train_samples_per_second': 161.823, 'train_steps_per_second': 20.235, 'total_flos': 0.0, 'train_loss': 0.7222974192746336, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оценка"
      ],
      "metadata": {
        "id": "WLbFsrnfoKKU"
      },
      "id": "WLbFsrnfoKKU"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer4.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "_0e7svK-CP6g",
        "outputId": "38804d2d-0d1f-4758-de8d-462725369b95"
      },
      "id": "_0e7svK-CP6g",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7420584498094028,\n",
              " 'eval_f1': 0.7413729629187614,\n",
              " 'eval_loss': 0.6639107465744019,\n",
              " 'eval_precision': 0.7412346170125702,\n",
              " 'eval_recall': 0.7420584498094028,\n",
              " 'eval_runtime': 1.1633,\n",
              " 'eval_samples_per_second': 676.543,\n",
              " 'eval_steps_per_second': 42.982}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task4_metrics = trainer4.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task4_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "xMYNbYXvr4DE",
        "outputId": "3b5540ef-4e5a-4043-eebe-b0343bdad367"
      },
      "id": "xMYNbYXvr4DE",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7157360406091371,\n",
              " 'test_f1': 0.7138717951452226,\n",
              " 'test_loss': 0.709484875202179,\n",
              " 'test_precision': 0.7129874486540948,\n",
              " 'test_recall': 0.7157360406091371,\n",
              " 'test_runtime': 1.2929,\n",
              " 'test_samples_per_second': 609.478,\n",
              " 'test_steps_per_second': 38.672}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7157360406091371\n",
        "\n",
        "'test_f1': 0.7138717951452226\n",
        "\n",
        "'test_loss': 0.709484875202179\n",
        "\n",
        "'test_precision': 0.7129874486540948\n",
        "\n",
        "'test_recall': 0.7157360406091371"
      ],
      "metadata": {
        "id": "1hAbxq8erxF9"
      },
      "id": "1hAbxq8erxF9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5: Сравнение моделей\n",
        "Для выполнения пункта 5 нужно выбрать одну из моделей; логично это делать, основываясь на метриках. Посмотрим еще раз, как показали себя разные модели:"
      ],
      "metadata": {
        "id": "5QNEQJhLov-f"
      },
      "id": "5QNEQJhLov-f"
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics = {'SentimentClassifier': task1_metrics,\n",
        "               'SentimentClassifierWithCLS': task2_metrics,\n",
        "               'BertForSequenceClassification': task3_metrics,\n",
        "               'SentimentClassifierAllCLS': task4_metrics}"
      ],
      "metadata": {
        "id": "lEVP7u4owc3u"
      },
      "id": "lEVP7u4owc3u",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "QHHa9s7zwBm7",
        "outputId": "7fb558a4-e148-4319-fd7f-f566ce78d006"
      },
      "id": "QHHa9s7zwBm7",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         SentimentClassifier  SentimentClassifierWithCLS  \\\n",
              "test_loss                           0.700706                    0.726509   \n",
              "test_accuracy                       0.719543                    0.727157   \n",
              "test_f1                             0.717525                    0.724980   \n",
              "test_precision                      0.716574                    0.724495   \n",
              "test_recall                         0.719543                    0.727157   \n",
              "test_runtime                        1.277900                    1.269000   \n",
              "test_samples_per_second           616.649000                  620.961000   \n",
              "test_steps_per_second              39.127000                   39.401000   \n",
              "epoch                               3.000000                    3.000000   \n",
              "\n",
              "                         BertForSequenceClassification  \\\n",
              "test_loss                                     0.699814   \n",
              "test_accuracy                                 0.718274   \n",
              "test_f1                                       0.717462   \n",
              "test_precision                                0.716919   \n",
              "test_recall                                   0.718274   \n",
              "test_runtime                                  1.272100   \n",
              "test_samples_per_second                     619.469000   \n",
              "test_steps_per_second                        39.306000   \n",
              "epoch                                         3.000000   \n",
              "\n",
              "                         SentimentClassifierAllCLS  \n",
              "test_loss                                 0.709485  \n",
              "test_accuracy                             0.715736  \n",
              "test_f1                                   0.713872  \n",
              "test_precision                            0.712987  \n",
              "test_recall                               0.715736  \n",
              "test_runtime                              1.292900  \n",
              "test_samples_per_second                 609.478000  \n",
              "test_steps_per_second                    38.672000  \n",
              "epoch                                     3.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58698657-e073-4dfb-8028-28c3135fdfd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentClassifier</th>\n",
              "      <th>SentimentClassifierWithCLS</th>\n",
              "      <th>BertForSequenceClassification</th>\n",
              "      <th>SentimentClassifierAllCLS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>test_loss</th>\n",
              "      <td>0.700706</td>\n",
              "      <td>0.726509</td>\n",
              "      <td>0.699814</td>\n",
              "      <td>0.709485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_accuracy</th>\n",
              "      <td>0.719543</td>\n",
              "      <td>0.727157</td>\n",
              "      <td>0.718274</td>\n",
              "      <td>0.715736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_f1</th>\n",
              "      <td>0.717525</td>\n",
              "      <td>0.724980</td>\n",
              "      <td>0.717462</td>\n",
              "      <td>0.713872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_precision</th>\n",
              "      <td>0.716574</td>\n",
              "      <td>0.724495</td>\n",
              "      <td>0.716919</td>\n",
              "      <td>0.712987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_recall</th>\n",
              "      <td>0.719543</td>\n",
              "      <td>0.727157</td>\n",
              "      <td>0.718274</td>\n",
              "      <td>0.715736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_runtime</th>\n",
              "      <td>1.277900</td>\n",
              "      <td>1.269000</td>\n",
              "      <td>1.272100</td>\n",
              "      <td>1.292900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_samples_per_second</th>\n",
              "      <td>616.649000</td>\n",
              "      <td>620.961000</td>\n",
              "      <td>619.469000</td>\n",
              "      <td>609.478000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_steps_per_second</th>\n",
              "      <td>39.127000</td>\n",
              "      <td>39.401000</td>\n",
              "      <td>39.306000</td>\n",
              "      <td>38.672000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58698657-e073-4dfb-8028-28c3135fdfd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58698657-e073-4dfb-8028-28c3135fdfd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58698657-e073-4dfb-8028-28c3135fdfd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Немного лучше других сработала вторая модель, использующая выход CLS-токена."
      ],
      "metadata": {
        "id": "Jnbl7knh4KJy"
      },
      "id": "Jnbl7knh4KJy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Проиллюстрировать работу одной из моделей (2 балла)\n",
        "Выберите на сайте Google Play три понравившихся вам отзыва, относящиеся к разным классам. Покажите, как на них работает любая из обученных моделей."
      ],
      "metadata": {
        "id": "q1oOtMZCkFT3"
      },
      "id": "q1oOtMZCkFT3"
    },
    {
      "cell_type": "code",
      "source": [
        "negative = \"\"\"It's not worth using unless you are premium subscriber. And now I \n",
        "have no possibility to pay for subscription due to sanctions against my country.\n",
        " Sadly something tells me that I would never be able to use Spotify again. \n",
        "Without premium this application is straight torture. Do you think life will \n",
        "get back to normal and this discrimination of innocent people will end? I've \n",
        "already lost all hope.\"\"\"\n",
        "\n",
        "neutral = \"\"\"The sound quality on spotify is perfect, but there's one thing that\n",
        " really bothers me. On my laptop, whenever I listen to songs by spotify, they \n",
        "keep stuttering. I've tried all ways to stop it, such as reinstalling, \n",
        "refreshing, but it doesn't work. I can still enjoy music on youtube so this \n",
        "problem seems to be related to spotify.\"\"\"\n",
        "\n",
        "positive = \"\"\"Great music app. I've been using this app for about 5 or 6 years. \n",
        "Awesome. Great selection. I get free hulu because of it. I got a free Google \n",
        "home mini a few years ago thru Spotify and I use that everyday! I've found a \n",
        "lot of new artists and the recommendations are awesome. Only $10 a month for \n",
        "something I use for hours everyday\"\"\""
      ],
      "metadata": {
        "id": "MnM4eXXew9XG"
      },
      "id": "MnM4eXXew9XG",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review, tokenizer, model, max_length=160, device='cuda'):\n",
        "    encoded_review = tokenizer.encode_plus(review,\n",
        "                                           max_length=max_length,\n",
        "                                           add_special_tokens=True, \n",
        "                                           return_token_type_ids=True,\n",
        "                                           padding='max_length',\n",
        "                                           return_attention_mask=True,\n",
        "                                           return_tensors='pt',\n",
        "                                           truncation=True).to(device)\n",
        "    input_ids = encoded_review['input_ids'].to(device)\n",
        "    attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "    output = model(input_ids, attention_mask)[0]\n",
        "    prediction = torch.argmax(output)\n",
        "\n",
        "    return class_names[prediction]"
      ],
      "metadata": {
        "id": "d715sbQpzFyQ"
      },
      "id": "d715sbQpzFyQ",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяем модель на отзывах выше (на всякий случай сохраняю выдачу в виде текста, т.к. разведка донесла, что гитхаб нынче съедает принты при загрузке):"
      ],
      "metadata": {
        "id": "4ASVUcFrA8-V"
      },
      "id": "4ASVUcFrA8-V"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(negative, tokenizer, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oQrpdqPS7V7l",
        "outputId": "3a1bce6c-ab71-4b3c-b593-c2100c84ee0c"
      },
      "id": "oQrpdqPS7V7l",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'negative'"
      ],
      "metadata": {
        "id": "hrvrAQrTA3SY"
      },
      "id": "hrvrAQrTA3SY"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(neutral, tokenizer, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sAYdJTZR-C8y",
        "outputId": "0172ef4e-e6d1-4c3e-9483-21ee572bae90"
      },
      "id": "sAYdJTZR-C8y",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'neutral'"
      ],
      "metadata": {
        "id": "V--jn05NA5Hx"
      },
      "id": "V--jn05NA5Hx"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(positive, tokenizer, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TSbaf-Qq-GO-",
        "outputId": "71ba5ca8-3fdb-4083-cd02-a8b5b49e308c"
      },
      "id": "TSbaf-Qq-GO-",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'positive'"
      ],
      "metadata": {
        "id": "Wt8xCLwcA7BB"
      },
      "id": "Wt8xCLwcA7BB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель хорошо себя показала на выбранных отзывах, но это может быть удачным совпадением, учитывая общее качество. Выбирая отзывы на Google Play, я заметила, что люди имеют тенденцию писать в отзывах на 3 звезды только плохое, не отмечая положительные стороны. Такие отзывы, на мой взгляд, должны вызывать трудности у модели. Проверим на одном из таких примеров:"
      ],
      "metadata": {
        "id": "RZj1cVmc_ZIe"
      },
      "id": "RZj1cVmc_ZIe"
    },
    {
      "cell_type": "code",
      "source": [
        "check = \"\"\"Offline mode no longer usable! I'm a premium user. I download my \n",
        "playlists to my mobile over Wi-Fi. I used to use offline mode to save \n",
        "unnecessary data usage. But If I select Offline-mode now, in max two days, \n",
        "my songs are unplayable. I need to leave it online. Also, bigger Playlists \n",
        "loop the same songs over and over. Even if there are 5000 songs in the Playlist,\n",
        "if shuffle is selected, it will play just the same 100. (Cache cleared \n",
        "regularly) Extremely laggy on older devices.\"\"\"\n",
        "\n",
        "predict_sentiment(check, tokenizer, model3)  # true = 'neutral'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N1xicjzS_3-0",
        "outputId": "8d1e2029-746a-44bf-a720-4612a3710211"
      },
      "id": "N1xicjzS_3-0",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'negative'"
      ],
      "metadata": {
        "id": "NoSbZ05ZDUtu"
      },
      "id": "NoSbZ05ZDUtu"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "klykova_nn_methods_hw4_bert",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}