{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaklykova/neuromethods/blob/main/hw4/klykova_nn_methods_hw4_bert_NEW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20101271",
      "metadata": {
        "id": "20101271"
      },
      "source": [
        "# –î/–ó 4: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ BERT –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "### –í—ã–ø–æ–ª–Ω–∏–ª–∞ –ï–ª–∏–∑–∞–≤–µ—Ç–∞ –ö–ª—ã–∫–æ–≤–∞, –ë–ö–õ181"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
      ],
      "metadata": {
        "id": "kPLAbc-xdb4Z"
      },
      "id": "kPLAbc-xdb4Z"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "90d34261",
      "metadata": {
        "id": "90d34261"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0caa1c8a",
      "metadata": {
        "id": "0caa1c8a"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, Trainer, TrainingArguments, \\\n",
        "    BertForSequenceClassification\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pylab import rcParams\n",
        "from textwrap import wrap\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
        "    precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9056999d",
      "metadata": {
        "id": "9056999d"
      },
      "outputs": [],
      "source": [
        "seed = 117\n",
        "# random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda') if torch.cuda.is_available()\\\n",
        "                              else torch.device('cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ohlV3fn5Qz",
        "outputId": "fd8cbafc-f983-4b9b-eef9-a4a4880bb995"
      },
      "id": "J8ohlV3fn5Qz",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
      ],
      "metadata": {
        "id": "VbTnVj2rn9kx"
      },
      "id": "VbTnVj2rn9kx"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73d9c2f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73d9c2f4",
        "outputId": "795c868b-e02b-4391-b9e5-de78a78d718a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 74.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "100% 7.17M/7.17M [00:00<00:00, 167MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef6bc8f1",
      "metadata": {
        "id": "ef6bc8f1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤, –±–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç:"
      ],
      "metadata": {
        "id": "MqQDfLo1c8oy"
      },
      "id": "MqQDfLo1c8oy"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9fcda166",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "9fcda166",
        "outputId": "5f958547-c164-4d47-bdae-bd966a3656a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'review score')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATQUlEQVR4nO3df/BddX3n8eeL4I/WagETKSZsw9a0Lm1XZFPERa0L0xCtFcZBS2eVVNlJdwcd2W1rZWdnabHM2rGtVWudMpIKritSKUvqOsUsoqArPxJAhFCGLMJCBkhKEKWO7mLf+8f9xFySb/h8Q3O+55t8n4+ZO/ec9/mcc9/f+0deOT/uOakqJEl6OoeM3YAkaf4zLCRJXYaFJKnLsJAkdRkWkqSuQ8duYAiLFy+u5cuXj92GJB1QNm3a9HdVtWSmZQdlWCxfvpyNGzeO3YYkHVCS3L+3ZR6GkiR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYOGRZL7knwjyW1JNrbaEUk2JLmnvR/e6kny4SRbktye5Pip7axp4+9JsmbIniVJe5qLPYt/VVXHVdXKNv9e4JqqWgFc0+YBXgesaK+1wMdgEi7A+cArgBOA83cGjCRpbozxC+7TgNe26UuALwG/0+qX1uRpTDckOSzJUW3shqraAZBkA7Aa+PTctq2D2UkfOWnsFgbx1Xd9dewWdJAYes+igC8k2ZRkbasdWVUPtemHgSPb9FLggal1H2y1vdWfIsnaJBuTbNy+ffv+/BskacEbes/iVVW1NcmLgA1J/nZ6YVVVkv3yXNequgi4CGDlypU+K1aS9qNB9yyqamt73wZcyeScwyPt8BLtfVsbvhU4emr1Za22t7okaY4MFhZJnpfk+TungVXAHcB6YOcVTWuAq9r0euCsdlXUicDj7XDV1cCqJIe3E9urWk2SNEeGPAx1JHBlkp2f89+q6m+S3AxcnuRs4H7gLW3854HXA1uA7wJvB6iqHUneB9zcxl2w82S3JGluDBYWVXUv8LIZ6o8Cp8xQL+CcvWxrHbBuf/coSZodf8EtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtfgYZFkUZJbk3yuzR+T5MYkW5J8JsmzW/05bX5LW758ahvntfrdSU4dumdJ0lPNxZ7Fu4G7pub/APhgVb0EeAw4u9XPBh5r9Q+2cSQ5FjgT+FlgNfBnSRbNQd+SpGbQsEiyDPhl4ONtPsDJwGfbkEuA09v0aW2etvyUNv404LKq+n5VfRPYApwwZN+SpKcaes/iT4D3AP/Q5l8IfKuqnmzzDwJL2/RS4AGAtvzxNv6H9RnWkSTNgcHCIskbgG1VtWmoz9jt89Ym2Zhk4/bt2+fiIyVpwRhyz+Ik4I1J7gMuY3L46UPAYUkObWOWAVvb9FbgaIC2/MeBR6frM6zzQ1V1UVWtrKqVS5Ys2f9/jSQtYIOFRVWdV1XLqmo5kxPUX6yqfw1cC5zRhq0BrmrT69s8bfkXq6pa/cx2tdQxwArgpqH6liTt6dD+kP3ud4DLkvw+cCtwcatfDHwyyRZgB5OAoaruTHI5sBl4Ejinqn4w921L0sI1J2FRVV8CvtSm72WGq5mq6nvAm/ey/oXAhcN1KEl6Ov6CW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSuwcIiyXOT3JTk60nuTPJ7rX5MkhuTbEnymSTPbvXntPktbfnyqW2d1+p3Jzl1qJ4lSTMbcs/i+8DJVfUy4DhgdZITgT8APlhVLwEeA85u488GHmv1D7ZxJDkWOBP4WWA18GdJFg3YtyRpN4OFRU080Waf1V4FnAx8ttUvAU5v06e1edryU5Kk1S+rqu9X1TeBLcAJQ/UtSdrToOcskixKchuwDdgA/G/gW1X1ZBvyILC0TS8FHgBoyx8HXjhdn2EdSdIcGDQsquoHVXUcsIzJ3sBLh/qsJGuTbEyycfv27UN9jCQtSHNyNVRVfQu4FnglcFiSQ9uiZcDWNr0VOBqgLf9x4NHp+gzrTH/GRVW1sqpWLlmyZJC/Q5IWqiGvhlqS5LA2/SPALwF3MQmNM9qwNcBVbXp9m6ct/2JVVauf2a6WOgZYAdw0VN+SpD0d2h8CSa6pqlN6td0cBVzSrlw6BLi8qj6XZDNwWZLfB24FLm7jLwY+mWQLsIPJFVBU1Z1JLgc2A08C51TVD2b/J0qS/rGeNiySPBf4UWBxksOBtEUvoHOSuapuB14+Q/1eZriaqaq+B7x5L9u6ELjw6T5Pkva3P/3Nvx67hf3unX/0K89ovd6exW8A5wIvBjaxKyy+DfzpM/pESdIB52nDoqo+BHwoybuq6iNz1JMkaZ6Z1TmLqvpIkn8JLJ9ep6ouHagvSdI8MtsT3J8Efgq4Ddh5crkAw0KSFoBZhQWwEji2Xcoq6SD25df84tgt7He/eN2Xx27hgDfb31ncAfzEkI1Ikuav2e5ZLAY2J7mJyd1kAaiqNw7SlSRpXpltWPzukE1Ikua32V4N5QE/SVrAZns11HeYXP0E8Gwmz6b4+6p6wVCNSZLmj9nuWTx/5/TUA4lOHKopSdL8ss93nW1PwPvvgM/ClqQFYraHod40NXsIk99dfG+Qjgb2L3774Pwd4aYPnDV2C5IOYrO9Gmr6NoVPAvcxORQlSVoAZnvO4u1DNyJJmr9mdc4iybIkVybZ1l5XJFk2dHOSpPlhtie4/4LJ401f3F5/3WqSpAVgtucsllTVdDh8Ism5QzSkufN/Lvj5sVsYxD/5z98YuwXpoDPbPYtHk7w1yaL2eivw6JCNSZLmj9mGxTuAtwAPAw8BZwC/PlBPkqR5ZraHoS4A1lTVYwBJjgD+kEmISJIOcrPds/jnO4MCoKp2AC8fpiVJ0nwz27A4JMnhO2fansVs90okSQe42f6D/0fA15L8ZZt/M3DhMC1Jkuab2f6C+9IkG4GTW+lNVbV5uLYkSfPJrA8ltXAwICRpAdrnW5RLkhYew0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2DhUWSo5Ncm2RzkjuTvLvVj0iyIck97f3wVk+SDyfZkuT2JMdPbWtNG39PkjVD9SxJmtmQexZPAr9ZVccCJwLnJDkWeC9wTVWtAK5p8wCvA1a011rgY/DDW4ucD7wCOAE4f/rWI5Kk4Q0WFlX1UFXd0qa/A9wFLAVOAy5pwy4BTm/TpwGX1sQNwGFJjgJOBTZU1Y52M8MNwOqh+pYk7WlOzlkkWc7kLrU3AkdW1UNt0cPAkW16KfDA1GoPttre6pKkOTJ4WCT5MeAK4Nyq+vb0sqoqoPbT56xNsjHJxu3bt++PTUqSmkHDIsmzmATFp6rqr1r5kXZ4ifa+rdW3AkdPrb6s1fZWf4qquqiqVlbVyiVLluzfP0SSFrghr4YKcDFwV1X98dSi9cDOK5rWAFdN1c9qV0WdCDzeDlddDaxKcng7sb2q1SRJc2TIBxidBLwN+EaS21rtPwLvBy5PcjZwP5NnewN8Hng9sAX4LvB2mDyVL8n7gJvbuAvak/okSXNksLCoqq8A2cviU2YYX8A5e9nWOmDd/utOkrQv/AW3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpa7CwSLIuybYkd0zVjkiyIck97f3wVk+SDyfZkuT2JMdPrbOmjb8nyZqh+pUk7d2QexafAFbvVnsvcE1VrQCuafMArwNWtNda4GMwCRfgfOAVwAnA+TsDRpI0dwYLi6q6DtixW/k04JI2fQlw+lT90pq4ATgsyVHAqcCGqtpRVY8BG9gzgCRJA5vrcxZHVtVDbfph4Mg2vRR4YGrcg622t/oekqxNsjHJxu3bt+/friVpgRvtBHdVFVD7cXsXVdXKqlq5ZMmS/bVZSRJzHxaPtMNLtPdtrb4VOHpq3LJW21tdkjSH5jos1gM7r2haA1w1VT+rXRV1IvB4O1x1NbAqyeHtxPaqVpMkzaFDh9pwkk8DrwUWJ3mQyVVN7wcuT3I2cD/wljb888DrgS3Ad4G3A1TVjiTvA25u4y6oqt1PmkuSBjZYWFTVr+1l0SkzjC3gnL1sZx2wbj+2JknaR/6CW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSuAyYskqxOcneSLUneO3Y/krSQHBBhkWQR8FHgdcCxwK8lOXbcriRp4TggwgI4AdhSVfdW1f8FLgNOG7knSVowUlVj99CV5AxgdVX9mzb/NuAVVfXOqTFrgbVt9meAu+e80T0tBv5u7CbmCb+LXfwudvG72GU+fBc/WVVLZlpw6Fx3MpSqugi4aOw+piXZWFUrx+5jPvC72MXvYhe/i13m+3dxoByG2gocPTW/rNUkSXPgQAmLm4EVSY5J8mzgTGD9yD1J0oJxQByGqqonk7wTuBpYBKyrqjtHbms25tVhsZH5Xezid7GL38Uu8/q7OCBOcEuSxnWgHIaSJI3IsJAkdRkWA0iyLsm2JHeM3cuYkhyd5Nokm5PcmeTdY/c0liTPTXJTkq+37+L3xu5pbEkWJbk1yefG7mVMSe5L8o0ktyXZOHY/e+M5iwEkeQ3wBHBpVf3c2P2MJclRwFFVdUuS5wObgNOravPIrc25JAGeV1VPJHkW8BXg3VV1w8itjSbJfwBWAi+oqjeM3c9YktwHrKyqsX+Q97TcsxhAVV0H7Bi7j7FV1UNVdUub/g5wF7B03K7GURNPtNlntdeC/Z9akmXALwMfH7sXzY5hoTmRZDnwcuDGcTsZTzvschuwDdhQVQv2uwD+BHgP8A9jNzIPFPCFJJvabYvmJcNCg0vyY8AVwLlV9e2x+xlLVf2gqo5jcgeCE5IsyEOUSd4AbKuqTWP3Mk+8qqqOZ3JX7XPaYex5x7DQoNrx+SuAT1XVX43dz3xQVd8CrgVWj93LSE4C3tiO1V8GnJzkv47b0niqamt73wZcyeQu2/OOYaHBtJO6FwN3VdUfj93PmJIsSXJYm/4R4JeAvx23q3FU1XlVtayqljO5dc8Xq+qtI7c1iiTPaxd/kOR5wCpgXl5FaVgMIMmnga8BP5PkwSRnj93TSE4C3sbkf463tdfrx25qJEcB1ya5ncm9zjZU1YK+ZFQAHAl8JcnXgZuA/1FVfzNyTzPy0llJUpd7FpKkLsNCktRlWEiSugwLSVKXYSFJ6jIspH2U5MVJPjt2H9Jc8tJZLWjth4OpqoPmHkVJDq2qJ8fuQwcX9yy04CRZnuTuJJcy+bXs0Ul+O8nNSW7f+ayJJO9Pcs7Uer+b5Lfa+ne02qIkH5ha9zda/aNJ3timr0yyrk2/I8mFu/WzKMknktzRnmvw71v9JUn+Z3sGxi1JfioTH5ga+6tt7GuTXJ9kPbB5b31Jz9ShYzcgjWQFsKaqbkiyqs2fAARY327m9hkmd0f9aFvnLcCpwKKp7ZwNPF5Vv5DkOcBXk3wBuB54NbCeyW3Zj2rjX83kfkjTjgOW7nz2yc7bggCfAt5fVVcmeS6T/9y9qY1/GbAYuDnJdW388cDPVdU3291L9+irqr75jL8xLWjuWWihun/qwUOr2utW4BbgpcCKqroVeFE7R/Ey4LGqemC37awCzmq3Hr8ReCGT4LkeeHWSY4HNwCPtYVCvBP7Xbtu4F/inST6SZDXw7Xa/oKVVdSVAVX2vqr4LvAr4dLuD7SPAl4FfaNu5aSoM9taX9Iy4Z6GF6u+npgP8l6r68xnG/SVwBvATTPY0dhfgXVV19R4LJnsIq4HrgCOY7Jk80R4E9UNV9VgLo1OBf9vGPZNH0O7+N83Yl/RMuGchwdXAO9pzN0iyNMmL2rLPMLkz6hlMgmOmdf9duxU7SX663T0U4AbgXCZhcT3wW+39KZIsBg6pqiuA/wQc3wLlwSSntzHPSfKjbf1fbecklgCvYXIDun3pS9pn7llowauqLyT5Z8DXJhdH8QTwViYP6LmzHRLaWlUPzbD6x4HlwC3tyqrtwOlt2fXAqqrakuR+JnsXe4QFk3Maf5Fk53/ezmvvbwP+PMkFwP8D3szkeQevBL7O5Alr76mqh5O8dB/6kvaZl85Kkro8DCVJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrr+P5NvNxqoAjZJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0a9f4c8f",
      "metadata": {
        "id": "0a9f4c8f"
      },
      "outputs": [],
      "source": [
        "def to_sentiment(rating):\n",
        "    rating = int(rating)\n",
        "    if rating <= 2:\n",
        "        return 0\n",
        "    elif rating == 3:\n",
        "        return 1\n",
        "    else: \n",
        "        return 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "metadata": {
        "id": "Cc6HjIkjc64A"
      },
      "id": "Cc6HjIkjc64A",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d1f2a648",
      "metadata": {
        "id": "d1f2a648"
      },
      "outputs": [],
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "82d51efc",
      "metadata": {
        "id": "82d51efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "5acb770c-3c3d-4861-9e3f-67c7b701552c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'negative'), Text(0, 0, 'neutral'), Text(0, 0, 'positive')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è\n",
        "–†–µ—à–∏—Ç–µ –∑–∞–¥–∞—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–º –≤ —Ç–µ—Ç—Ä–∞–¥–∫–µ –∫–æ—Ä–ø—É—Å–µ, –∏—Å–ø–æ–ª—å–∑—É—è –ø–∞–π–ø–ª–∞–π–Ω —Å Trainer –æ—Ç HuggingFace.\n",
        "\n",
        "1. DONE –æ–±—É—á–∏—Ç–µ —Ç—É –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –º—ã —Ä–∞–∑–±–∏—Ä–∞–ª–∏ –Ω–∞ –∑–∞–Ω—è—Ç–∏–∏ (–∫–ª–∞—Å—Å SentimentClassifier –∏–∑ —Ç–µ—Ç—Ä–∞–¥–∫–∏) -- 2 –±–∞–ª–ª–∞\n",
        "\n",
        "2. DONE –∏–∑–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –ø–æ–º–∏–º–æ –≤—ã—Ö–æ–¥–∞ —Å –ø—É–ª–ª–µ—Ä-—Å–ª–æ—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥ cls-—Ç–æ–∫–µ–Ω–∞ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è. -- 3 –±–∞–ª–ª–∞\n",
        "\n",
        "3. DONE –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –∫ –¥–∞–Ω–Ω—ã–º –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—Ç–∏–ø–∞ BertForSequenceClassification) -- 2 –±–∞–ª–ª–∞\n",
        "\n",
        "4. DONE –∞–≥—Ä–µ–≥–∏—Ä—É–π—Ç–µ cls-—Ç–æ–∫–µ–Ω—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–µ–≤, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ -- 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∞–ª–ª–∞\n",
        "\n",
        "5. DONE –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–∞ —Å–∞–π—Ç–µ google play —Ç—Ä–∏ –ø–æ–Ω—Ä–∞–≤–∏–≤—à–∏—Ö—Å—è –≤–∞–º –æ—Ç–∑—ã–≤–∞, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ —Ä–∞–∑–Ω—ã–º –∫–ª–∞—Å—Å–∞–º. –ü–æ–∫–∞–∂–∏—Ç–µ, –∫–∞–∫ –Ω–∞ –Ω–∏—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—é–±–∞—è –∏–∑ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π -- 2 –±–∞–ª–ª–∞\n",
        "\n",
        "DONE –û–±—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è: (1 –±–∞–ª–ª) –î–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —á—Ç–æ–±—ã –∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —Å—Ä–∞–≤–Ω–∏—Ç—å –º–µ–∂–¥—É —Å–æ–±–æ–π.\n",
        "\n",
        "DONE –ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –≤–∞—à–∏ —Ä–µ—à–µ–Ω–∏—è –≤ –∫–æ–¥–µ.\n",
        "\n",
        "DONE –î–ª—è –∫–∞–∂–¥–æ–π –∏–∑ –º–æ–¥–µ–ª–µ–π –Ω—É–∂–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ.\n",
        "\n",
        "DONE –í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—É—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º, –∫—Ä–æ–º–µ bert-base-cased."
      ],
      "metadata": {
        "id": "6jGXSgTfkqT_"
      },
      "id": "6jGXSgTfkqT_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1: –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Å SentimentClassifier (2 –±–∞–ª–ª–∞)"
      ],
      "metadata": {
        "id": "PMff0u3beAJC"
      },
      "id": "PMff0u3beAJC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "–î–µ–ª–∏–º –Ω–∞ —Ç–µ—Å—Ç –∏ —Ç—Ä–µ–π–Ω:"
      ],
      "metadata": {
        "id": "wDt0IZQJhqhk"
      },
      "id": "wDt0IZQJhqhk"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=seed)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=seed)"
      ],
      "metadata": {
        "id": "TlYtbPKkf7o0"
      },
      "id": "TlYtbPKkf7o0",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–Ø –±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å [prajjwal1/bert-mini](https://huggingface.co/prajjwal1/bert-mini), –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∞ –º–∞–ª–æ –≤–µ—Å–∏—Ç, –∞ —Ç–∞–∫–∂–µ –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞–µ—Ç—Å—è –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç."
      ],
      "metadata": {
        "id": "ClN1EwTUgIHp"
      },
      "id": "ClN1EwTUgIHp"
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'prajjwal1/bert-mini'"
      ],
      "metadata": {
        "id": "1eoc94I1egTo"
      },
      "id": "1eoc94I1egTo",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "Oux4gJhgeUnL"
      },
      "id": "Oux4gJhgeUnL",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "yk_zE69Ge3W4"
      },
      "id": "yk_zE69Ge3W4",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(df_train['content'].to_list(), truncation=True, \n",
        "                            padding=True, return_token_type_ids=False, \n",
        "                            return_attention_mask=True, max_length=160)\n",
        "val_encodings = tokenizer(df_val['content'].to_list(), truncation=True, \n",
        "                          padding=True, return_token_type_ids=False,\n",
        "                          return_attention_mask=True, max_length=160)\n",
        "test_encodings = tokenizer(df_test['content'].to_list(), truncation=True, \n",
        "                           padding=True, return_token_type_ids=False,\n",
        "                           return_attention_mask=True, max_length=160)"
      ],
      "metadata": {
        "id": "gYjlFAIKghcn"
      },
      "id": "gYjlFAIKghcn",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = GPReviewDataset(train_encodings, df_train['sentiment'].to_list())\n",
        "val_dataset = GPReviewDataset(val_encodings, df_val['sentiment'].to_list())\n",
        "test_dataset = GPReviewDataset(test_encodings, df_test['sentiment'].to_list())"
      ],
      "metadata": {
        "id": "gm0ioS0XfoMz"
      },
      "id": "gm0ioS0XfoMz",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–µ—Ç—Ä–∏–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–µ–π–Ω–µ—Ä–∞"
      ],
      "metadata": {
        "id": "199opnMUjB5f"
      },
      "id": "199opnMUjB5f"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds,\n",
        "                                                               average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "p1JV4cbVjF_3"
      },
      "id": "p1JV4cbVjF_3",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:"
      ],
      "metadata": {
        "id": "fg8Mf186BmTU"
      },
      "id": "fg8Mf186BmTU"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=100,\n",
        ")"
      ],
      "metadata": {
        "id": "UTcDnofZj99Q"
      },
      "id": "UTcDnofZj99Q",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–æ–¥–µ–ª—å\n",
        "–î–æ–±–∞–≤–ª—è–µ–º –≤ –º–æ–¥–µ–ª—å –ø–æ–¥—Å—á–µ—Ç –ª–æ—Å—Å–∞ (–∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—é):"
      ],
      "metadata": {
        "id": "J7hNMuinh9dh"
      },
      "id": "J7hNMuinh9dh"
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False)\n",
        "        output = self.drop(pooled_output)\n",
        "        output = self.out(output)\n",
        "        if labels is not None:\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(output, labels)\n",
        "            return loss, output\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "DJ1jqCq0k51q"
      },
      "id": "DJ1jqCq0k51q",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = SentimentClassifier(n_classes=3)\n",
        "model1 = model1.to(DEVICE)"
      ],
      "metadata": {
        "id": "DYk7sd5znS5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa98b94-b160-435c-a624-2d1ecdece79e"
      },
      "id": "DYk7sd5znS5Y",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4a7ea2bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4a7ea2bf",
        "outputId": "022d6fa2-000a-420f-c232-ba52e555c9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.996700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.931800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.968600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.883900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.829400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.825600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.849600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.826700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.782200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.792600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.797600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.769500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.788100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.755000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.702300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.722700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.661000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.629300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.651100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.754000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.662200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.648200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.620300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.616700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.668500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.623000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.598800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.599200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.575200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.536900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.567800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.661800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.526400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.616100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.548800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.585700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.552600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.554500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.573300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.560300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.7124012172266987, metrics={'train_runtime': 263.8687, 'train_samples_per_second': 161.114, 'train_steps_per_second': 20.146, 'total_flos': 0.0, 'train_loss': 0.7124012172266987, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "trainer1 = Trainer(\n",
        "    model=model1,                        # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer1.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û—Ü–µ–Ω–∫–∞"
      ],
      "metadata": {
        "id": "HApSFe_lhvGP"
      },
      "id": "HApSFe_lhvGP"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "1GiIe2nICFwW",
        "outputId": "c449c7c5-fbd7-4406-e4f7-4416ea9ddc37"
      },
      "id": "1GiIe2nICFwW",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7458703939008895,\n",
              " 'eval_f1': 0.7449001912160426,\n",
              " 'eval_loss': 0.6661240458488464,\n",
              " 'eval_precision': 0.7444538860445467,\n",
              " 'eval_recall': 0.7458703939008895,\n",
              " 'eval_runtime': 1.1396,\n",
              " 'eval_samples_per_second': 690.617,\n",
              " 'eval_steps_per_second': 43.877}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_metrics = trainer1.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task1_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "PGihkIHPhiGr",
        "outputId": "382094c5-db15-4c14-c9a6-183161832e7a"
      },
      "id": "PGihkIHPhiGr",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7195431472081218,\n",
              " 'test_f1': 0.7175250820150627,\n",
              " 'test_loss': 0.700705885887146,\n",
              " 'test_precision': 0.7165735299433978,\n",
              " 'test_recall': 0.7195431472081218,\n",
              " 'test_runtime': 1.2779,\n",
              " 'test_samples_per_second': 616.649,\n",
              " 'test_steps_per_second': 39.127}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7195431472081218\n",
        "\n",
        "'test_f1': 0.7175250820150627\n",
        "\n",
        "'test_loss': 0.700705885887146\n",
        "\n",
        "'test_precision': 0.7165735299433978\n",
        "\n",
        "'test_recall': 0.7195431472081218"
      ],
      "metadata": {
        "id": "4m9HZ51juyDL"
      },
      "id": "4m9HZ51juyDL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CLS-—Ç–æ–∫–µ–Ω (3 –±–∞–ª–ª–∞)\n",
        "–ò–∑–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –ø–æ–º–∏–º–æ –≤—ã—Ö–æ–¥–∞ —Å –ø—É–ª–ª–µ—Ä-—Å–ª–æ—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥ cls-—Ç–æ–∫–µ–Ω–∞ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è."
      ],
      "metadata": {
        "id": "vN7FXr0Ye55d"
      },
      "id": "vN7FXr0Ye55d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "jm_mmdyVhyo2"
      },
      "id": "jm_mmdyVhyo2"
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifierWithCLS(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        # –≤ –¥–≤–∞ —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: —Å –ø—É–ª–ª–µ—Ä-—Å–ª–æ—è –∏ CLS\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size * 2, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        last_hidden_state, pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False)\n",
        "        # –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥—ã —Å CLS\n",
        "        cls_hidden = last_hidden_state[:, 0, :]\n",
        "        stacked_layers = torch.hstack([cls_hidden, pooled_output])\n",
        "        # –¥–∞–ª—å—à–µ –≤—Å–µ —Ç–æ –∂–µ —Å–∞–º–æ–µ\n",
        "        output = self.drop(stacked_layers)\n",
        "        output = self.out(output)\n",
        "        if labels is not None:\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(output, labels)\n",
        "            return loss, output\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "PA0YrTzNf696"
      },
      "id": "PA0YrTzNf696",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SentimentClassifierWithCLS(n_classes=3)\n",
        "model2 = model2.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdM1PRluhONp",
        "outputId": "174f2668-52d4-403f-d605-595b52db65f5"
      },
      "id": "fdM1PRluhONp",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-mini.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = Trainer(\n",
        "    model=model2,                         # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer2.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sKYUY_bVhUbN",
        "outputId": "6a6fa63f-5dc8-49db-cf63-35e070ee1e09"
      },
      "id": "sKYUY_bVhUbN",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.142300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.092300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.941400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.910300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.969300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.861200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.834600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.789100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.788600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.778600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.803000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.741300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.716800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.671400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.735600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.688400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.721300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.737400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.645900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.639900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.622800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.724500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.636900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.673400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.644900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.626000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.578900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.558500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.546700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.530200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.564800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.630500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.520700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.609300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.570300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.550800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.537000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.557200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.546700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.7063673872800588, metrics={'train_runtime': 267.5421, 'train_samples_per_second': 158.902, 'train_steps_per_second': 19.87, 'total_flos': 0.0, 'train_loss': 0.7063673872800588, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û—Ü–µ–Ω–∫–∞"
      ],
      "metadata": {
        "id": "MQU4-j_uh1b9"
      },
      "id": "MQU4-j_uh1b9"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ip8K1b5TCJCd",
        "outputId": "1248854a-bf83-4152-8e2e-4d2b3bf74239"
      },
      "id": "ip8K1b5TCJCd",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7534942820838628,\n",
              " 'eval_f1': 0.7510092553606023,\n",
              " 'eval_loss': 0.6870903372764587,\n",
              " 'eval_precision': 0.7505587063502279,\n",
              " 'eval_recall': 0.7534942820838628,\n",
              " 'eval_runtime': 1.14,\n",
              " 'eval_samples_per_second': 690.337,\n",
              " 'eval_steps_per_second': 43.859}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task2_metrics = trainer2.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task2_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "7m4imZCvhZx3",
        "outputId": "11cb9742-bdc9-4cd9-fb9d-3eac85657245"
      },
      "id": "7m4imZCvhZx3",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7271573604060914,\n",
              " 'test_f1': 0.7249801696477138,\n",
              " 'test_loss': 0.7265090346336365,\n",
              " 'test_precision': 0.7244949466213112,\n",
              " 'test_recall': 0.7271573604060914,\n",
              " 'test_runtime': 1.269,\n",
              " 'test_samples_per_second': 620.961,\n",
              " 'test_steps_per_second': 39.401}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7271573604060914\n",
        "\n",
        "'test_f1': 0.7249801696477138\n",
        "\n",
        "'test_loss': 0.7265090346336365\n",
        "\n",
        "'test_precision': 0.7244949466213112\n",
        "\n",
        "'test_recall': 0.7271573604060914"
      ],
      "metadata": {
        "id": "51DhG3BziM9d"
      },
      "id": "51DhG3BziM9d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å BertForSequenceClassification (2 –±–∞–ª–ª–∞)"
      ],
      "metadata": {
        "id": "IFd2hX7_h_Ak"
      },
      "id": "IFd2hX7_h_Ak"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–æ–¥–µ–ª—å\n"
      ],
      "metadata": {
        "id": "M_ySLOPWiIRE"
      },
      "id": "M_ySLOPWiIRE"
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME,\n",
        "                                                       num_labels=3)\n",
        "model3 = model3.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0r-cBl4helm",
        "outputId": "b0b8db73-e296-4efd-9414-b647971e2514"
      },
      "id": "j0r-cBl4helm",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3 = Trainer(\n",
        "    model=model3,                        # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer3.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bC9tM5Ucijy_",
        "outputId": "7baae2c2-f3f2-4682-f999-dc6cc0380767"
      },
      "id": "bC9tM5Ucijy_",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.044900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.946800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.906400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.917000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.845100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.792400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.793800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.815900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.800900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.779000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.785000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.762700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.775500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.737900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.697700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.669600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.714600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.670900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.660900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.666800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.696400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.631500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.656300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.721600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.659000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.627800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.606400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.624000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.674500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.622500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.573000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.568700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.559200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.529800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.604400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.579500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.643000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.611200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.564700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.581500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.544500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.543100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.558600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.531200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.546800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.6979088459452621, metrics={'train_runtime': 270.9737, 'train_samples_per_second': 156.89, 'train_steps_per_second': 19.618, 'total_flos': 131665753915200.0, 'train_loss': 0.6979088459452621, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û—Ü–µ–Ω–∫–∞"
      ],
      "metadata": {
        "id": "mkdykPBNivQA"
      },
      "id": "mkdykPBNivQA"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "sO9uxpfUCMtk",
        "outputId": "656499b9-f7c9-4712-a302-b2b4a801521c"
      },
      "id": "sO9uxpfUCMtk",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7433290978398983,\n",
              " 'eval_f1': 0.7413411404516946,\n",
              " 'eval_loss': 0.6564545631408691,\n",
              " 'eval_precision': 0.740587164439763,\n",
              " 'eval_recall': 0.7433290978398983,\n",
              " 'eval_runtime': 1.1366,\n",
              " 'eval_samples_per_second': 692.418,\n",
              " 'eval_steps_per_second': 43.991}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task3_metrics = trainer3.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task3_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ULb5nVj8im6u",
        "outputId": "19794353-90fa-4f11-e1c0-a3cae779d820"
      },
      "id": "ULb5nVj8im6u",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7182741116751269,\n",
              " 'test_f1': 0.7174620470984623,\n",
              " 'test_loss': 0.6998140811920166,\n",
              " 'test_precision': 0.7169186564878467,\n",
              " 'test_recall': 0.7182741116751269,\n",
              " 'test_runtime': 1.2721,\n",
              " 'test_samples_per_second': 619.469,\n",
              " 'test_steps_per_second': 39.306}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7182741116751269\n",
        "\n",
        "'test_f1': 0.7174620470984623\n",
        "\n",
        "'test_loss': 0.6998140811920166\n",
        "\n",
        "'test_precision': 0.7169186564878467\n",
        "\n",
        "'test_recall': 0.7182741116751269"
      ],
      "metadata": {
        "id": "jZOxM8Y1i-we"
      },
      "id": "jZOxM8Y1i-we"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å CLS-—Ç–æ–∫–µ–Ω—ã –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–µ–≤ (2 –±–æ–Ω—É—Å–∞)"
      ],
      "metadata": {
        "id": "tviJ_-eakU3h"
      },
      "id": "tviJ_-eakU3h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "MLWH2A37n3YO"
      },
      "id": "MLWH2A37n3YO"
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifierAllCLS(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # –∑–¥–µ—Å—å –¥–æ–±–∞–≤–∏–ª–∏—Å—å –≤—Å–µ —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏\n",
        "        last_hidden_state, pooled_output, hidden_states = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False,\n",
        "            output_hidden_states=True)\n",
        "        # –¥–æ–±–∞–≤–ª—è–µ–º CLS –≤—Å–µ—Ö —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤\n",
        "        all_cls_hidden = [layer[:, 0, :] for layer in hidden_states]\n",
        "        # –ø–æ–ª—É—á–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ\n",
        "        mean_cls = torch.mean(torch.stack(all_cls_hidden, dim=0), dim=0)\n",
        "        # –¥–∞–ª—å—à–µ –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ\n",
        "        output = self.drop(mean_cls)\n",
        "        output = self.out(output)\n",
        "        if labels is not None:\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(output, labels)\n",
        "            return loss, output\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "8cAJ6X8jlUNR"
      },
      "id": "8cAJ6X8jlUNR",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = SentimentClassifierAllCLS(n_classes=3)\n",
        "model4 = model4.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6IXtUXpnzTl",
        "outputId": "b73c5f0f-dc99-4071-c311-b82279db605f"
      },
      "id": "O6IXtUXpnzTl",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-mini/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3baee60ec6103a88d346bbdcc74e81e9027137f2d2a589e1031cb569ce2c1101.0eab9dd6f6881374d284b4961e8bd581e67d6829624515d67c7cd26d65d8aaaf\n",
            "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-mini.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer4 = Trainer(\n",
        "    model=model4,                        # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer4.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WpDBEVtOn7nA",
        "outputId": "efe25207-5d08-43e9-9106-6aad788e7432"
      },
      "id": "WpDBEVtOn7nA",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 14171\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5316' max='5316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5316/5316 04:22, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.878300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.843500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.841600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.821200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.790500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.788800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.824100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.797200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.770600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.785700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.755200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.729800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.688200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.754700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.683600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.681400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.708400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.654700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.729100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.656500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.650700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.723600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.641400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.670700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.671300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.628400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.593400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.589800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.572900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.628100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.598700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.655500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.554400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.636700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.562100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.592600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.576600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.588500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.582700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.572500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.557100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.574000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5316, training_loss=0.7222974192746336, metrics={'train_runtime': 262.7125, 'train_samples_per_second': 161.823, 'train_steps_per_second': 20.235, 'total_flos': 0.0, 'train_loss': 0.7222974192746336, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û—Ü–µ–Ω–∫–∞"
      ],
      "metadata": {
        "id": "WLbFsrnfoKKU"
      },
      "id": "WLbFsrnfoKKU"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer4.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "_0e7svK-CP6g",
        "outputId": "38804d2d-0d1f-4758-de8d-462725369b95"
      },
      "id": "_0e7svK-CP6g",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 787\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.7420584498094028,\n",
              " 'eval_f1': 0.7413729629187614,\n",
              " 'eval_loss': 0.6639107465744019,\n",
              " 'eval_precision': 0.7412346170125702,\n",
              " 'eval_recall': 0.7420584498094028,\n",
              " 'eval_runtime': 1.1633,\n",
              " 'eval_samples_per_second': 676.543,\n",
              " 'eval_steps_per_second': 42.982}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task4_metrics = trainer4.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "task4_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "xMYNbYXvr4DE",
        "outputId": "3b5540ef-4e5a-4043-eebe-b0343bdad367"
      },
      "id": "xMYNbYXvr4DE",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 788\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'test_accuracy': 0.7157360406091371,\n",
              " 'test_f1': 0.7138717951452226,\n",
              " 'test_loss': 0.709484875202179,\n",
              " 'test_precision': 0.7129874486540948,\n",
              " 'test_recall': 0.7157360406091371,\n",
              " 'test_runtime': 1.2929,\n",
              " 'test_samples_per_second': 609.478,\n",
              " 'test_steps_per_second': 38.672}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'test_accuracy': 0.7157360406091371\n",
        "\n",
        "'test_f1': 0.7138717951452226\n",
        "\n",
        "'test_loss': 0.709484875202179\n",
        "\n",
        "'test_precision': 0.7129874486540948\n",
        "\n",
        "'test_recall': 0.7157360406091371"
      ],
      "metadata": {
        "id": "1hAbxq8erxF9"
      },
      "id": "1hAbxq8erxF9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
        "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—É–Ω–∫—Ç–∞ 5 –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω—É –∏–∑ –º–æ–¥–µ–ª–µ–π; –ª–æ–≥–∏—á–Ω–æ —ç—Ç–æ –¥–µ–ª–∞—Ç—å, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –º–µ—Ç—Ä–∏–∫–∞—Ö. –ü–æ—Å–º–æ—Ç—Ä–∏–º –µ—â–µ —Ä–∞–∑, –∫–∞–∫ –ø–æ–∫–∞–∑–∞–ª–∏ —Å–µ–±—è —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏:"
      ],
      "metadata": {
        "id": "5QNEQJhLov-f"
      },
      "id": "5QNEQJhLov-f"
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics = {'SentimentClassifier': task1_metrics,\n",
        "               'SentimentClassifierWithCLS': task2_metrics,\n",
        "               'BertForSequenceClassification': task3_metrics,\n",
        "               'SentimentClassifierAllCLS': task4_metrics}"
      ],
      "metadata": {
        "id": "lEVP7u4owc3u"
      },
      "id": "lEVP7u4owc3u",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "QHHa9s7zwBm7",
        "outputId": "7fb558a4-e148-4319-fd7f-f566ce78d006"
      },
      "id": "QHHa9s7zwBm7",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         SentimentClassifier  SentimentClassifierWithCLS  \\\n",
              "test_loss                           0.700706                    0.726509   \n",
              "test_accuracy                       0.719543                    0.727157   \n",
              "test_f1                             0.717525                    0.724980   \n",
              "test_precision                      0.716574                    0.724495   \n",
              "test_recall                         0.719543                    0.727157   \n",
              "test_runtime                        1.277900                    1.269000   \n",
              "test_samples_per_second           616.649000                  620.961000   \n",
              "test_steps_per_second              39.127000                   39.401000   \n",
              "epoch                               3.000000                    3.000000   \n",
              "\n",
              "                         BertForSequenceClassification  \\\n",
              "test_loss                                     0.699814   \n",
              "test_accuracy                                 0.718274   \n",
              "test_f1                                       0.717462   \n",
              "test_precision                                0.716919   \n",
              "test_recall                                   0.718274   \n",
              "test_runtime                                  1.272100   \n",
              "test_samples_per_second                     619.469000   \n",
              "test_steps_per_second                        39.306000   \n",
              "epoch                                         3.000000   \n",
              "\n",
              "                         SentimentClassifierAllCLS  \n",
              "test_loss                                 0.709485  \n",
              "test_accuracy                             0.715736  \n",
              "test_f1                                   0.713872  \n",
              "test_precision                            0.712987  \n",
              "test_recall                               0.715736  \n",
              "test_runtime                              1.292900  \n",
              "test_samples_per_second                 609.478000  \n",
              "test_steps_per_second                    38.672000  \n",
              "epoch                                     3.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58698657-e073-4dfb-8028-28c3135fdfd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentClassifier</th>\n",
              "      <th>SentimentClassifierWithCLS</th>\n",
              "      <th>BertForSequenceClassification</th>\n",
              "      <th>SentimentClassifierAllCLS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>test_loss</th>\n",
              "      <td>0.700706</td>\n",
              "      <td>0.726509</td>\n",
              "      <td>0.699814</td>\n",
              "      <td>0.709485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_accuracy</th>\n",
              "      <td>0.719543</td>\n",
              "      <td>0.727157</td>\n",
              "      <td>0.718274</td>\n",
              "      <td>0.715736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_f1</th>\n",
              "      <td>0.717525</td>\n",
              "      <td>0.724980</td>\n",
              "      <td>0.717462</td>\n",
              "      <td>0.713872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_precision</th>\n",
              "      <td>0.716574</td>\n",
              "      <td>0.724495</td>\n",
              "      <td>0.716919</td>\n",
              "      <td>0.712987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_recall</th>\n",
              "      <td>0.719543</td>\n",
              "      <td>0.727157</td>\n",
              "      <td>0.718274</td>\n",
              "      <td>0.715736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_runtime</th>\n",
              "      <td>1.277900</td>\n",
              "      <td>1.269000</td>\n",
              "      <td>1.272100</td>\n",
              "      <td>1.292900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_samples_per_second</th>\n",
              "      <td>616.649000</td>\n",
              "      <td>620.961000</td>\n",
              "      <td>619.469000</td>\n",
              "      <td>609.478000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_steps_per_second</th>\n",
              "      <td>39.127000</td>\n",
              "      <td>39.401000</td>\n",
              "      <td>39.306000</td>\n",
              "      <td>38.672000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58698657-e073-4dfb-8028-28c3135fdfd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58698657-e073-4dfb-8028-28c3135fdfd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58698657-e073-4dfb-8028-28c3135fdfd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–µ–º–Ω–æ–≥–æ –ª—É—á—à–µ –¥—Ä—É–≥–∏—Ö —Å—Ä–∞–±–æ—Ç–∞–ª–∞ –≤—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –≤—ã—Ö–æ–¥ CLS-—Ç–æ–∫–µ–Ω–∞."
      ],
      "metadata": {
        "id": "Jnbl7knh4KJy"
      },
      "id": "Jnbl7knh4KJy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: –ü—Ä–æ–∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –æ–¥–Ω–æ–π –∏–∑ –º–æ–¥–µ–ª–µ–π (2 –±–∞–ª–ª–∞)\n",
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞ —Å–∞–π—Ç–µ Google Play —Ç—Ä–∏ –ø–æ–Ω—Ä–∞–≤–∏–≤—à–∏—Ö—Å—è –≤–∞–º –æ—Ç–∑—ã–≤–∞, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ —Ä–∞–∑–Ω—ã–º –∫–ª–∞—Å—Å–∞–º. –ü–æ–∫–∞–∂–∏—Ç–µ, –∫–∞–∫ –Ω–∞ –Ω–∏—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—é–±–∞—è –∏–∑ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."
      ],
      "metadata": {
        "id": "q1oOtMZCkFT3"
      },
      "id": "q1oOtMZCkFT3"
    },
    {
      "cell_type": "code",
      "source": [
        "negative = \"\"\"It's not worth using unless you are premium subscriber. And now I \n",
        "have no possibility to pay for subscription due to sanctions against my country.\n",
        " Sadly something tells me that I would never be able to use Spotify again. \n",
        "Without premium this application is straight torture. Do you think life will \n",
        "get back to normal and this discrimination of innocent people will end? I've \n",
        "already lost all hope.\"\"\"\n",
        "\n",
        "neutral = \"\"\"The sound quality on spotify is perfect, but there's one thing that\n",
        " really bothers me. On my laptop, whenever I listen to songs by spotify, they \n",
        "keep stuttering. I've tried all ways to stop it, such as reinstalling, \n",
        "refreshing, but it doesn't work. I can still enjoy music on youtube so this \n",
        "problem seems to be related to spotify.\"\"\"\n",
        "\n",
        "positive = \"\"\"Great music app. I've been using this app for about 5 or 6 years. \n",
        "Awesome. Great selection. I get free hulu because of it. I got a free Google \n",
        "home mini a few years ago thru Spotify and I use that everyday! I've found a \n",
        "lot of new artists and the recommendations are awesome. Only $10 a month for \n",
        "something I use for hours everyday\"\"\""
      ],
      "metadata": {
        "id": "MnM4eXXew9XG"
      },
      "id": "MnM4eXXew9XG",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review, tokenizer, model, max_length=160, device='cuda'):\n",
        "    encoded_review = tokenizer.encode_plus(review,\n",
        "                                           max_length=max_length,\n",
        "                                           add_special_tokens=True, \n",
        "                                           return_token_type_ids=True,\n",
        "                                           padding='max_length',\n",
        "                                           return_attention_mask=True,\n",
        "                                           return_tensors='pt',\n",
        "                                           truncation=True).to(device)\n",
        "    input_ids = encoded_review['input_ids'].to(device)\n",
        "    attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "    output = model(input_ids, attention_mask)[0]\n",
        "    prediction = torch.argmax(output)\n",
        "\n",
        "    return class_names[prediction]"
      ],
      "metadata": {
        "id": "d715sbQpzFyQ"
      },
      "id": "d715sbQpzFyQ",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –æ—Ç–∑—ã–≤–∞—Ö –≤—ã—à–µ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Å–æ—Ö—Ä–∞–Ω—è—é –≤—ã–¥–∞—á—É –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞, —Ç.–∫. —Ä–∞–∑–≤–µ–¥–∫–∞ –¥–æ–Ω–µ—Å–ª–∞, —á—Ç–æ –≥–∏—Ç—Ö–∞–± –Ω—ã–Ω—á–µ —Å—ä–µ–¥–∞–µ—Ç –ø—Ä–∏–Ω—Ç—ã –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ):"
      ],
      "metadata": {
        "id": "4ASVUcFrA8-V"
      },
      "id": "4ASVUcFrA8-V"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(negative, tokenizer, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oQrpdqPS7V7l",
        "outputId": "3a1bce6c-ab71-4b3c-b593-c2100c84ee0c"
      },
      "id": "oQrpdqPS7V7l",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'negative'"
      ],
      "metadata": {
        "id": "hrvrAQrTA3SY"
      },
      "id": "hrvrAQrTA3SY"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(neutral, tokenizer, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sAYdJTZR-C8y",
        "outputId": "0172ef4e-e6d1-4c3e-9483-21ee572bae90"
      },
      "id": "sAYdJTZR-C8y",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'neutral'"
      ],
      "metadata": {
        "id": "V--jn05NA5Hx"
      },
      "id": "V--jn05NA5Hx"
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(positive, tokenizer, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TSbaf-Qq-GO-",
        "outputId": "71ba5ca8-3fdb-4083-cd02-a8b5b49e308c"
      },
      "id": "TSbaf-Qq-GO-",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'positive'"
      ],
      "metadata": {
        "id": "Wt8xCLwcA7BB"
      },
      "id": "Wt8xCLwcA7BB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ —Å–µ–±—è –ø–æ–∫–∞–∑–∞–ª–∞ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö, –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–∞—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º, —É—á–∏—Ç—ã–≤–∞—è –æ–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ. –í—ã–±–∏—Ä–∞—è –æ—Ç–∑—ã–≤—ã –Ω–∞ Google Play, —è –∑–∞–º–µ—Ç–∏–ª–∞, —á—Ç–æ –ª—é–¥–∏ –∏–º–µ—é—Ç —Ç–µ–Ω–¥–µ–Ω—Ü–∏—é –ø–∏—Å–∞—Ç—å –≤ –æ—Ç–∑—ã–≤–∞—Ö –Ω–∞ 3 –∑–≤–µ–∑–¥—ã —Ç–æ–ª—å–∫–æ –ø–ª–æ—Ö–æ–µ, –Ω–µ –æ—Ç–º–µ—á–∞—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã. –¢–∞–∫–∏–µ –æ—Ç–∑—ã–≤—ã, –Ω–∞ –º–æ–π –≤–∑–≥–ª—è–¥, –¥–æ–ª–∂–Ω—ã –≤—ã–∑—ã–≤–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —É –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ —Ç–∞–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤:"
      ],
      "metadata": {
        "id": "RZj1cVmc_ZIe"
      },
      "id": "RZj1cVmc_ZIe"
    },
    {
      "cell_type": "code",
      "source": [
        "check = \"\"\"Offline mode no longer usable! I'm a premium user. I download my \n",
        "playlists to my mobile over Wi-Fi. I used to use offline mode to save \n",
        "unnecessary data usage. But If I select Offline-mode now, in max two days, \n",
        "my songs are unplayable. I need to leave it online. Also, bigger Playlists \n",
        "loop the same songs over and over. Even if there are 5000 songs in the Playlist,\n",
        "if shuffle is selected, it will play just the same 100. (Cache cleared \n",
        "regularly) Extremely laggy on older devices.\"\"\"\n",
        "\n",
        "predict_sentiment(check, tokenizer, model3)  # true = 'neutral'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N1xicjzS_3-0",
        "outputId": "8d1e2029-746a-44bf-a720-4612a3710211"
      },
      "id": "N1xicjzS_3-0",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'negative'"
      ],
      "metadata": {
        "id": "NoSbZ05ZDUtu"
      },
      "id": "NoSbZ05ZDUtu"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "klykova_nn_methods_hw4_bert",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}